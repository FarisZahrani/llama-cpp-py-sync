name: Validate Bindings

on:
  push:
    tags: ['*']
  workflow_dispatch:

jobs:
  validate-cffi-surface:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: .python-version

      - name: Resolve pinned llama.cpp SHA
        id: pinned
        run: |
          python - <<'PY'
          import json, os, pathlib, re, sys

          root = pathlib.Path('.')
          sha = ''

          state = root / '.llama_cpp_sync_state.json'
          if state.exists():
              try:
                  sha = json.loads(state.read_text(encoding='utf-8')).get('last_sync_sha', '')
              except Exception:
                  sha = ''

          if not sha:
              bindings = root / 'src' / 'llama_cpp_py_sync' / '_cffi_bindings.py'
              if bindings.exists():
                  m = re.search(r"llama\.cpp commit:\s*([0-9a-fA-F]{7,40})", bindings.read_text(encoding='utf-8'))
                  if m:
                      sha = m.group(1)

          if not sha:
              print('Could not resolve pinned llama.cpp SHA', file=sys.stderr)
              sys.exit(1)

          print(f"sha={sha}")
          print(f"sha={sha}", file=open(os.environ['GITHUB_OUTPUT'], 'a'))
          PY

      - name: Resolve bindings timestamp
        id: bind_ts
        run: |
          python - <<'PY'
          import os, pathlib, re, sys

          bindings = pathlib.Path('src/llama_cpp_py_sync/_cffi_bindings.py')
          ts = ''
          if bindings.exists():
              m = re.search(r"Generated:\s*(.+)", bindings.read_text(encoding='utf-8'))
              if m:
                  ts = m.group(1).strip()

          if not ts:
              print('Could not resolve bindings timestamp', file=sys.stderr)
              sys.exit(1)

          print(f"timestamp={ts}")
          print(f"timestamp={ts}", file=open(os.environ['GITHUB_OUTPUT'], 'a'))
          PY

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install cffi numpy

      - name: Clone llama.cpp headers (no build)
        env:
          LLAMA_CPP_REPO: https://github.com/ggerganov/llama.cpp.git
        run: |
          set -euo pipefail

          UPSTREAM_SHA="${{ steps.pinned.outputs.sha }}"
          if [ -z "${UPSTREAM_SHA}" ]; then
            echo "Missing pinned SHA" >&2
            exit 1
          fi

          rm -rf vendor/llama.cpp
          mkdir -p vendor/llama.cpp
          git init vendor/llama.cpp
          git -C vendor/llama.cpp remote add origin "${LLAMA_CPP_REPO}"
          git -C vendor/llama.cpp fetch --depth 1 origin "${UPSTREAM_SHA}"
          git -C vendor/llama.cpp checkout --detach FETCH_HEAD

      - name: Regenerate bindings (check only)
        run: |
          # Use the pinned upstream SHA for reproducible headers in the generated banner.
          UPSTREAM_SHA="${{ steps.pinned.outputs.sha }}"
          python scripts/gen_bindings.py --commit-sha "$UPSTREAM_SHA" --timestamp "${{ steps.bind_ts.outputs.timestamp }}"

      - name: Validate header, structs/enums, and signatures
        run: |
          python scripts/validate_cffi_surface.py --check-structs --check-enums --check-signatures

      - name: Ensure committed bindings are up-to-date
        run: |
          git diff --exit-code -- src/llama_cpp_py_sync/_cffi_bindings.py
